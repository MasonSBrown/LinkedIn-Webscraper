name: Run LinkedIn Scraper

on:
  push:
    branches: [ main ]
  schedule:
    - cron: "*/1 * * * *"
    # # Runs every 10 minutes from 8AM to 3:50PM PST on Monday to Friday
    # - cron: "*/10 16-23 * * 1-5"
    # # Runs every 10 minutes from 4:00 PM - 5:50 PM PST (UTC 00:00 - 01:50 on Tue-Sat)
    # - cron: "*/10 0-1 * * 2-6"
  workflow_dispatch:

permissions:
  contents: write  # Grant write permission to contents

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2
        with:
          persist-credentials: true  # Enable automatic token authentication

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper
        env:
          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}
          TWILIO_AUTH_TOKEN: ${{ secrets.TWILIO_AUTH_TOKEN }}
          TWILIO_PHONE_NUMBER: ${{ secrets.TWILIO_PHONE_NUMBER }}
          YOUR_PHONE_NUMBER: ${{ secrets.YOUR_PHONE_NUMBER }}
          LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
          LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
          COOKIES_B64: ${{ secrets.COOKIES_B64 }}
        run: |
          python scraper.py

      - name: Configure Git
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and push changes
        run: |
          git add job_cache.json
          git diff --cached --quiet || git commit -m "Update job_cache.json"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

